{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "562aab34-e99b-400a-9948-90f009e82ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from google.cloud import storage\n",
    "from skopt import BayesSearchCV\n",
    "from tsextract.feature_extraction.extract import build_features_forecast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from scripts.modeltrain.regressionalgorithm import RegressionAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "87f3118e-7fbe-4f47-b33c-17f99cf7b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_lagged_df(df, label_count):\n",
    "    try:\n",
    "        if label_count != 0:\n",
    "            scaler_features = StandardScaler().fit(df[df.columns.values[:-label_count]])\n",
    "            scaler_label = StandardScaler().fit(\n",
    "                np.array(df[df.columns.values[-label_count:]]).reshape(-1, label_count))\n",
    "        else:\n",
    "            scaler_features = StandardScaler().fit(df[df.columns.values])\n",
    "            scaler_label = scaler_features\n",
    "\n",
    "        return scaler_features, scaler_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7140d218-dd89-4d62-b6e4-b4a3dfa7e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(pred_series, last_actual_observation):\n",
    "    try:\n",
    "        series_undifferenced = pred_series.copy()\n",
    "        series_undifferenced.iat[0] = series_undifferenced.iat[0] + last_actual_observation\n",
    "        series_undifferenced = series_undifferenced.cumsum()\n",
    "\n",
    "        return series_undifferenced\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d22b73d3-7133-443b-b540-5b1bb40fb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast(model, range_start, range_end):\n",
    "    import datetime\n",
    "\n",
    "    feature_arrays = []\n",
    "    features_requests = model.features_requests\n",
    "    train_df = model.train_df\n",
    "    scaler_label = model.scaler_label\n",
    "    labels = model.labels\n",
    "    date_column = model.date_column\n",
    "    freq = model.freq\n",
    "    forecast_dfs = []\n",
    "\n",
    "    for label in labels:\n",
    "        df = pd.DataFrame({date_column: train_df.index, label: train_df[label]})\n",
    "        features_request = [fr for fr in features_requests if fr.get('name') == label][0]\n",
    "        features_request_copy = features_request.copy()\n",
    "        features_request_copy.pop(\"name\")\n",
    "        target_series = df[label]\n",
    "        build_forecast_df = build_features_forecast(target_series, features_request_copy, include_tzero=True)\n",
    "        forecast_dfs.append(build_forecast_df)\n",
    "        \n",
    "    tail = list(set([df.shape[0] for df in forecast_dfs]))\n",
    "    tail = tail[0]\n",
    "    \n",
    "    for build_forecast_df in forecast_dfs:\n",
    "        sub_scaler_features, sub_scaler_label = scale_lagged_df(build_forecast_df, 0)\n",
    "        scaled_features_forecast = sub_scaler_features.transform(build_forecast_df[-tail:])\n",
    "        feature_arrays.append(scaled_features_forecast)\n",
    "    \n",
    "    merged_array = np.concatenate(tuple(feature_arrays), axis=1)\n",
    "    pred = model.predict(merged_array[:, :-(len(labels))])\n",
    "    pred = scaler_label.inverse_transform(np.array(pred).reshape(-1, 1))\n",
    "\n",
    "    forecast_range = pd.date_range(start=train_df.index[-1] + datetime.timedelta(days=1), \n",
    "                                   end=train_df.index[-1] + datetime.timedelta(days=tail), \n",
    "                                   freq=freq)\n",
    "    print(forecast_range)\n",
    "    forecast_range = forecast_range.to_list()\n",
    "    \n",
    "    for i, l in enumerate(labels):\n",
    "        \n",
    "        df_pred = pd.DataFrame({date_column: forecast_range})\n",
    "        df_pred['pred_' + l] = np.ravel(pred[:tail, [i]])\n",
    "        try:\n",
    "            df_pred.set_index(date_column, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        target_series = df_pred['pred_' + l]\n",
    "        print(target_series)\n",
    "        volatility = target_series.groupby(target_series.index.day).std()\n",
    "        forecast_vol = target_series.index.map(lambda d: volatility.loc[d.day])\n",
    "        df_pred['forecast_vol'] = forecast_vol\n",
    "        target_series = target_series * forecast_vol\n",
    "\n",
    "        target_series = inverse_transform(target_series, train_df[l][-1])\n",
    "        df_pred['pred_' + l] = target_series\n",
    "        \n",
    "        temp_range_start = datetime.datetime.strptime(range_start, '%Y-%m-%d')\n",
    "        temp_range_end = datetime.datetime.strptime(range_end, '%Y-%m-%d')\n",
    "    \n",
    "        if temp_range_start and temp_range_end:\n",
    "            df_pred = df_pred.loc[(df_pred.index >= temp_range_start) & (df_pred.index <= temp_range_end)]\n",
    "\n",
    "        # plt.rcParams[\"figure.figsize\"] = (30, 7)\n",
    "        # # plt.scatter(train_df.index, train_df[l])\n",
    "        # # plt.plot(train_df.index, train_df[l], label=l + ' actual')\n",
    "        # plt.scatter(df_pred.index, df_pred['pred_' + l], label=l + ' forecast')\n",
    "        # plt.plot(df_pred.index, df_pred['pred_' + l], label=l + ' forecast')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "    return np.array(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fab1d70e-59ec-4f47-ae29-912ef84853be",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.load(open('input.json'))\n",
    "instances = body['instances']\n",
    "input_payload = instances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "118461c9-994a-414c-8dcd-1b90af642601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model_from_gcp():\n",
    "    error_message = \"\" \n",
    "    try:\n",
    "        storage_client = storage.Client(project=\"hclsw-gcp-xai\")\n",
    "        bucket = storage_client.get_bucket(\"regression-model\")\n",
    "\n",
    "        destination_file_name = \"model_storage/model.pkl\"\n",
    "        model_path = f\"%s/model.pkl\" % (\"mlp\")\n",
    "        blob = bucket.blob(model_path)\n",
    "\n",
    "        # Download the file to a destination\n",
    "        blob.download_to_filename(destination_file_name)\n",
    "        return error_message\n",
    "    except Exception as ex:\n",
    "        print (str(ex))\n",
    "        error_message = str(ex)\n",
    "    return error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "22e2d7b2-7000-4e2b-b8a8-0953d01a8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_model_from_gcp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c94946f1-77d3-4ce8-b7ff-58989b8d76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dill\n",
    "# import dill\n",
    "import sys\n",
    "sys.path.append('cuburt')\n",
    "# model = pickle.load(open('model_storage/model.pkl','rb'))\n",
    "model = joblib.load(\"model_storage/model-new.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8d40dbf5-8455-4d23-80ec-1a550559e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-05-01', '2016-05-02', '2016-05-03', '2016-05-04',\n",
      "               '2016-05-05', '2016-05-06', '2016-05-07', '2016-05-08',\n",
      "               '2016-05-09', '2016-05-10',\n",
      "               ...\n",
      "               '2017-12-21', '2017-12-22', '2017-12-23', '2017-12-24',\n",
      "               '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28',\n",
      "               '2017-12-29', '2017-12-30'],\n",
      "              dtype='datetime64[ns]', length=609, freq='D')\n",
      "date\n",
      "2016-05-01    1.510651\n",
      "2016-05-02    1.206081\n",
      "2016-05-03    1.236827\n",
      "2016-05-04    1.501203\n",
      "2016-05-05    1.216756\n",
      "                ...   \n",
      "2017-12-26   -0.154669\n",
      "2017-12-27   -0.414170\n",
      "2017-12-28   -0.274680\n",
      "2017-12-29   -0.477388\n",
      "2017-12-30   -0.242026\n",
      "Name: pred_dcoilwtico, Length: 609, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/s4_b5rbj2753sqbg81p7qkt40000gn/T/ipykernel_33337/3330098528.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  target_series = inverse_transform(target_series, train_df[l][-1])\n"
     ]
    }
   ],
   "source": [
    "output = get_forecast(model, '2017-05-31', '2017-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6a99adaa-5c80-4fb6-abb6-3e8902ab7666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': array([[82.71756488,  0.45656119],\n",
       "        [82.56858234,  0.57937611],\n",
       "        [82.6519082 ,  0.49779481],\n",
       "        [82.12199045,  0.67051688],\n",
       "        [81.93520312,  0.58459708],\n",
       "        [81.9574459 ,  0.53025176],\n",
       "        [81.81314965,  0.62611023],\n",
       "        [81.8981058 ,  0.46717942],\n",
       "        [81.44105496,  0.59462174],\n",
       "        [81.39367086,  0.59611465],\n",
       "        [81.21763002,  0.50186202],\n",
       "        [81.06715696,  0.39594249],\n",
       "        [80.92993111,  0.38818472],\n",
       "        [80.6750434 ,  0.45855794],\n",
       "        [80.49492185,  0.68028012],\n",
       "        [80.28437593,  0.55959632],\n",
       "        [80.13539161,  0.4246276 ],\n",
       "        [79.77260254,  0.63647824],\n",
       "        [79.55154511,  0.56161382],\n",
       "        [79.34917629,  0.43474136],\n",
       "        [79.08497812,  0.39127955],\n",
       "        [78.75227337,  0.46630509],\n",
       "        [78.52759952,  0.61800388],\n",
       "        [78.0720009 ,  0.50246888],\n",
       "        [77.96370443,  0.57400911],\n",
       "        [77.81179811,  0.60445762],\n",
       "        [77.52981281,  0.62410934],\n",
       "        [76.99281118,  0.63059053],\n",
       "        [76.82140541,  0.44447562],\n",
       "        [76.6876543 ,  0.4350167 ],\n",
       "        [76.53810364,  0.45322739]])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"predictions\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bde87-5b6b-4c96-8966-9d4b2073d8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
