{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "07704f86-7676-4bee-bf2a-1c0361343444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt  \n",
    "import joblib\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical\n",
    "\n",
    "from tsextract.feature_extraction.extract import build_features\n",
    "from statistics import mean, median, std\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "5108e2b2-109a-4372-ad7e-dafc5c803db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segregate_datetime(df, date_col):\n",
    "    try:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df['year'] = df[date_col].dt.year\n",
    "        df['month'] = df[date_col].dt.month\n",
    "        df['day'] = df[date_col].dt.day\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "682ae66c-84ef-4c96-836d-89a1f2880591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_interval(df, target_feature, freq='D'):\n",
    "    try:\n",
    "        sum_df = pd.DataFrame(df[target_feature].resample(freq).sum())\n",
    "        sum_df.dropna(inplace=True)\n",
    "\n",
    "        ave_df = pd.DataFrame(df[target_feature].resample(freq).mean())\n",
    "        ave_df.dropna(inplace=True)\n",
    "\n",
    "        if [pd.date_range(start=str(np.datetime_as_string(df.index.values[0], unit=freq)),\n",
    "                          end=str(np.datetime_as_string(df.index.values[-1], unit=freq))).difference(\n",
    "                df.index)] is not None:\n",
    "            sum_df = sum_df.resample(freq).interpolate(method='linear')\n",
    "            ave_df = ave_df.resample(freq).interpolate(method='linear')\n",
    "\n",
    "        return sum_df, ave_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "280af7dd-2f9b-4ed4-a346-202edbbe48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_series(series):\n",
    "    try:\n",
    "        avg, dev = series.mean(), series.std()\n",
    "        return (series - avg) / dev\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "8ea9aff2-e45c-44df-aa18-e1bdc7db3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_increasing_vol(series, series_range='M'):\n",
    "    transformed_series = series\n",
    "    try:\n",
    "        if series_range == 'D':\n",
    "            volatility = series.groupby(series.index.day).std()\n",
    "            vol = series.index.map(lambda d: volatility.loc[d.day])\n",
    "            transformed_series = series / vol\n",
    "        if series_range == 'M':\n",
    "            volatility = series.groupby(series.index.month).std()\n",
    "            vol = series.index.map(lambda d: volatility.loc[d.month])\n",
    "            transformed_series = series / vol\n",
    "        if series_range == 'Y':\n",
    "            volatility = series.groupby(series.index.year).std()\n",
    "            vol = series.index.map(lambda d: volatility.loc[d.year])\n",
    "            transformed_series = series / vol\n",
    "        return transformed_series\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "8855a097-7cf9-4021-82b5-d563145b5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(series):\n",
    "    try:\n",
    "        return series.diff()\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "6cbc5bc6-9430-49d4-aa55-82615f604806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adfuller_test(values):\n",
    "    # Augmented Dickey-Fuller test\n",
    "    dickey_fuller_res = adfuller(values)\n",
    "    print('test statistic: ', dickey_fuller_res[0], '\\np-value: ', dickey_fuller_res[1], '\\nstationary: ', str(dickey_fuller_res[1] <= 0.05))\n",
    "    print('Critical Values:')\n",
    "    for key, value in dickey_fuller_res[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "    return dickey_fuller_res[1] <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "aea3d219-8e72-4dd1-8a09-937a1367c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_pq(series, alpha, lag_size):\n",
    "    try:\n",
    "        # plot_acf(series, alpha=alpha)\n",
    "        acfs, aci = acf(series, nlags=math.ceil(len(series) * lag_size) - 1, alpha=alpha)\n",
    "        acfs = [i for i in range(0, len(acfs)) if acfs[i] < (np.array(aci[i]) - acfs[i])[0] or acfs[i] > (np.array(aci[i]) - acfs[i])[1]]\n",
    "        # plot_pacf(series, alpha=alpha)\n",
    "        pacfs, pci = pacf(series, nlags=math.ceil(len(series) * lag_size) - 1, alpha=alpha)\n",
    "        pacfs = [i for i in range(0, len(pacfs)) if pacfs[i] < (np.array(pci[i]) - pacfs[i])[0] or pacfs[i] > (np.array(pci[i]) - pacfs[i])[1]]\n",
    "        return acfs[-1], pacfs[-1]\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0612a194-6c42-474f-b15b-e65f1adee5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_request(target_col_df, label, window_size=False, diff_window_size=False, alpha=0.05, lag_size=0.25):\n",
    "    try:\n",
    "        features_request = {}\n",
    "        acfs, pacfs = get_optimal_pq(target_col_df, alpha, lag_size)\n",
    "        window_size = window_size if window_size else pacfs\n",
    "        diff_window_size = diff_window_size if diff_window_size else acfs\n",
    "        if diff_window_size != 0:\n",
    "            features_request[\"difference\"] = [diff_window_size, 1]\n",
    "        if window_size != 0:\n",
    "            features_request[\"window\"] = [window_size]\n",
    "        else:\n",
    "            features_request[\"window\"] = [0]\n",
    "        features_request['name'] = label\n",
    "\n",
    "        return features_request\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "8c20c302-d736-4a08-9290-b7d2196f4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_df(target_col_df, features_request , target_lag=3, include_tzero=True):\n",
    "    try:\n",
    "        build_df = build_features(target_col_df, features_request, target_lag=target_lag,\n",
    "                                  include_tzero=include_tzero)\n",
    "        return build_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "e7cc9398-36df-4fcf-84e8-a3fc78ea99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_lagged_df(df, label_count):\n",
    "    try:\n",
    "        if label_count != 0:\n",
    "            scaler_features = StandardScaler().fit(df[df.columns.values[:-label_count]])\n",
    "            scaler_label = StandardScaler().fit(\n",
    "                np.array(df[df.columns.values[-label_count:]]).reshape(-1, label_count))\n",
    "        else:\n",
    "            scaler_features = StandardScaler().fit(df[df.columns.values])\n",
    "            scaler_label = scaler_features\n",
    "\n",
    "        return scaler_features, scaler_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "0ebd7880-4210-4c7b-a4d2-a946c3c44bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lagged_df(df, label_count, train_size=0.7):\n",
    "    try:\n",
    "        scaler_features, scaler_label = scale_lagged_df(df, label_count)\n",
    "        scaled_features = scaler_features.transform(df[df.columns.values[:-label_count]])\n",
    "        scaled_label = scaler_label.transform(np.array(df[df.columns.values[-label_count:]]).reshape(-1, label_count))\n",
    "\n",
    "        ### Split data using train proportion of 0.7\n",
    "        train_size = int(scaled_features[:, :-1].shape[0] * train_size)\n",
    "\n",
    "        X_train, y_train = scaled_features[:train_size, :-label_count], scaled_label[:train_size, :]\n",
    "        X_test, y_test = scaled_features[train_size:, :-label_count], scaled_label[train_size:, :]\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "368e5d0c-eb2b-4575-a064-d67188e57883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpregressor(X_train, y_train, X_test, y_test, h_cells):\n",
    "    \n",
    "    mlp = MLPRegressor(\n",
    "                        hidden_layer_sizes=h_cells,\n",
    "                        max_iter=1000, \n",
    "                        activation='relu', \n",
    "                        solver='adam',  \n",
    "                        learning_rate='adaptive', \n",
    "                        validation_fraction=0.2,\n",
    "                        shuffle=False,\n",
    "                        random_state=10,\n",
    "                        batch_size=math.ceil(len(X_train)/10))\n",
    "    params = {\n",
    "            # \"n_iter_no_change\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            \"alpha\": Categorical(categories=[0.001, 0.05]),\n",
    "            }\n",
    "    \n",
    "    model = BayesSearchCV(mlp, params, n_jobs=3)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "5237b20c-7605-4ff2-ab3f-d6fa79afb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_series(df, labels, date_column, freq, training_range):\n",
    "    feature_dfs = []\n",
    "    label_dfs = []\n",
    "    features_requests = []\n",
    "    df_data_copy = df.copy()\n",
    "    for label in labels:\n",
    "        print('processing label '+label+'...')\n",
    "        print(df_data_copy)\n",
    "        df_data = pd.DataFrame({date_column: df_data_copy[date_column], label: df_data_copy[label]})\n",
    "        print(df_data.head(10))\n",
    "        initial_df = segregate_datetime(df_data, date_column)\n",
    "        initial_df.set_index(date_column, inplace=True)\n",
    "        print('created initial_df')\n",
    "        print(initial_df.head(10))\n",
    "        df_preprocessed_sum, df_preprocessed_ave = aggregate_interval(initial_df, label, freq)\n",
    "        print('created df_preprocessed_ave')\n",
    "        print(df_preprocessed_ave.head(10))\n",
    "        df_preprocessed_ave = df_preprocessed_ave[:training_range]\n",
    "        target_series = df_preprocessed_ave[label]\n",
    "        target_series_for_transform = target_series.copy()\n",
    "        target_series_for_transform = normalise_series(target_series_for_transform)\n",
    "        print('normalised series')\n",
    "        print(target_series_for_transform[10:])\n",
    "        if not adfuller_test(pd.Series(target_series_for_transform.values)):\n",
    "            target_series_for_transform = difference(target_series_for_transform)\n",
    "            target_series_for_transform.fillna(0, inplace=True)\n",
    "        print('tested stationarity of series')\n",
    "        target_series_for_transform = remove_increasing_vol(target_series_for_transform, freq)\n",
    "        print('transformed the series')\n",
    "        print(target_series_for_transform[30:])\n",
    "        features_request = create_features_request(target_series_for_transform, label)\n",
    "        print('features_request:', features_request)\n",
    "        print('created features request for series')\n",
    "        features_request_for_transform = features_request.copy()\n",
    "        features_request_for_transform.pop(\"name\")\n",
    "        lagged_df = create_lagged_df(target_series_for_transform, features_request_for_transform)\n",
    "        print('created ARMA features for series')\n",
    "        print(lagged_df.head(10))\n",
    "        target_df = pd.DataFrame({label + '_target': lagged_df[lagged_df.columns.values[-1]].values},\n",
    "                                 index=lagged_df.index)\n",
    "        print('created dataframe for label')\n",
    "        print(target_df.head(10))\n",
    "        feature_df = lagged_df.drop(columns=lagged_df.columns.values[-1])\n",
    "        print('dropped the label in series')\n",
    "        feature_df.rename(columns={col: label + '_' + col for col in feature_df.columns.values if label not in col}, inplace=True)\n",
    "        print('renamed ARMA features for series')\n",
    "        print(feature_df.head(10))\n",
    "        feature_df = pd.concat([feature_df, target_series], axis=1)\n",
    "        features_requests.append(features_request)\n",
    "        feature_dfs.append(feature_df)\n",
    "        label_dfs.append(target_df)\n",
    "\n",
    "    merged_feature_df = pd.concat(feature_dfs, axis=1)\n",
    "    print('merged features from list')\n",
    "    merged_label_df = pd.concat(label_dfs, axis=1)\n",
    "    print('merged labels from list')\n",
    "    train_df = pd.concat([merged_feature_df, merged_label_df], axis=1)\n",
    "    print('created series for training')\n",
    "    train_df.dropna(inplace=True, axis=0)\n",
    "    print('dropped nas in the series')\n",
    "\n",
    "    return train_df, features_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "c8d60501-edaa-4b0a-986b-9853641a51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, labels, date_column):\n",
    "    label_count = len(labels)\n",
    "    freq = 'D' #transfer to payload config\n",
    "    training_range = len(df) #transfer to payload config\n",
    "    train_df, features_requests = preprocess_series(df,labels,date_column,freq,training_range)\n",
    "    train_df_for_training = train_df.copy()\n",
    "    train_df_for_training.drop(columns=labels, inplace=True)\n",
    "    scaler_features, scaler_label = scale_lagged_df(train_df_for_training, label_count)\n",
    "    X_train, y_train, X_test, y_test = split_lagged_df(train_df_for_training, label_count)\n",
    "\n",
    "    feature_count = len(np.squeeze(np.array([train_df.columns.values[:-label_count]])))\n",
    "    h_cells = tuple([feature_count] * label_count)\n",
    "    model = mlpregressor(X_train, y_train, X_test, y_test, h_cells)\n",
    "\n",
    "    model.features_requests = features_requests\n",
    "    model.train_df = train_df\n",
    "    model.scaler_label = scaler_label\n",
    "    model.labels = labels\n",
    "    model.date_column = date_column\n",
    "    model.freq = freq\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d4474b75-ea73-4898-84f0-6923c5ec057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing label dcoilwtico...\n",
      "            date  dcoilwtico\n",
      "0     2013-01-01         NaN\n",
      "1     2013-01-02       93.14\n",
      "2     2013-01-03       92.97\n",
      "3     2013-01-04       93.12\n",
      "4     2013-01-07       93.20\n",
      "...          ...         ...\n",
      "1213  2017-08-25       47.65\n",
      "1214  2017-08-28       46.40\n",
      "1215  2017-08-29       46.46\n",
      "1216  2017-08-30       45.96\n",
      "1217  2017-08-31       47.26\n",
      "\n",
      "[1218 rows x 2 columns]\n",
      "         date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02       93.14\n",
      "2  2013-01-03       92.97\n",
      "3  2013-01-04       93.12\n",
      "4  2013-01-07       93.20\n",
      "5  2013-01-08       93.21\n",
      "6  2013-01-09       93.08\n",
      "7  2013-01-10       93.81\n",
      "8  2013-01-11       93.60\n",
      "9  2013-01-14       94.27\n",
      "created initial_df\n",
      "            dcoilwtico  year  month  day\n",
      "date                                    \n",
      "2013-01-01         NaN  2013      1    1\n",
      "2013-01-02       93.14  2013      1    2\n",
      "2013-01-03       92.97  2013      1    3\n",
      "2013-01-04       93.12  2013      1    4\n",
      "2013-01-07       93.20  2013      1    7\n",
      "2013-01-08       93.21  2013      1    8\n",
      "2013-01-09       93.08  2013      1    9\n",
      "2013-01-10       93.81  2013      1   10\n",
      "2013-01-11       93.60  2013      1   11\n",
      "2013-01-14       94.27  2013      1   14\n",
      "created df_preprocessed_ave\n",
      "            dcoilwtico\n",
      "date                  \n",
      "2013-01-02   93.140000\n",
      "2013-01-03   92.970000\n",
      "2013-01-04   93.120000\n",
      "2013-01-05   93.146667\n",
      "2013-01-06   93.173333\n",
      "2013-01-07   93.200000\n",
      "2013-01-08   93.210000\n",
      "2013-01-09   93.080000\n",
      "2013-01-10   93.810000\n",
      "2013-01-11   93.600000\n",
      "normalised series\n",
      "date\n",
      "2013-01-12    0.693627\n",
      "2013-01-13    0.702034\n",
      "2013-01-14    0.710441\n",
      "2013-01-15    0.672421\n",
      "2013-01-16    0.710817\n",
      "                ...   \n",
      "2016-04-29   -1.107338\n",
      "2016-04-30   -1.122771\n",
      "2016-05-01   -1.138205\n",
      "2016-05-02   -1.153638\n",
      "2016-05-03   -1.195046\n",
      "Freq: D, Name: dcoilwtico, Length: 1208, dtype: float64\n",
      "test statistic:  -0.2914943437729348 \n",
      "p-value:  0.9267003787086356 \n",
      "stationary:  False\n",
      "Critical Values:\n",
      "\t1%: -3.436\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "tested stationarity of series\n",
      "transformed the series\n",
      "date\n",
      "2013-02-01   -0.154238\n",
      "2013-02-02   -0.441809\n",
      "2013-02-03   -0.335769\n",
      "2013-02-04   -0.385995\n",
      "2013-02-05    0.553832\n",
      "                ...   \n",
      "2016-04-29   -0.056792\n",
      "2016-04-30   -0.358017\n",
      "2016-05-01   -0.332830\n",
      "2016-05-02   -0.434740\n",
      "2016-05-03   -0.886430\n",
      "Freq: D, Length: 1188, dtype: float64\n",
      "features_request: {'difference': [266, 1], 'window': [303], 'name': 'dcoilwtico'}\n",
      "created features request for series\n",
      "created ARMA features for series\n",
      "               T-303     T-302     T-301     T-300     T-299     T-298  \\\n",
      "Date                                                                     \n",
      "2013-11-01  0.000000 -0.136994  0.138958  0.031423  0.025515  0.031717   \n",
      "2013-11-02 -0.136994  0.138958  0.031423  0.025515  0.031717  0.010236   \n",
      "2013-11-03  0.138958  0.031423  0.025515  0.031717  0.010236 -0.144876   \n",
      "2013-11-04  0.031423  0.025515  0.031717  0.010236 -0.144876  0.665421   \n",
      "2013-11-05  0.025515  0.031717  0.010236 -0.144876  0.665421 -0.285653   \n",
      "2013-11-06  0.031717  0.010236 -0.144876  0.665421 -0.285653  0.191043   \n",
      "2013-11-07  0.010236 -0.144876  0.665421 -0.285653  0.191043  0.287149   \n",
      "2013-11-08 -0.144876  0.665421 -0.285653  0.191043  0.287149  0.222024   \n",
      "2013-11-09  0.665421 -0.285653  0.191043  0.287149  0.222024 -1.041217   \n",
      "2013-11-10 -0.285653  0.191043  0.287149  0.222024 -1.041217  1.214520   \n",
      "\n",
      "               T-297     T-296     T-295     T-294  ...  difference_266_1-8  \\\n",
      "Date                                                ...                       \n",
      "2013-11-01  0.010236 -0.144876  0.665421 -0.285653  ...            1.187271   \n",
      "2013-11-02 -0.144876  0.665421 -0.285653  0.191043  ...           -0.341341   \n",
      "2013-11-03  0.665421 -0.285653  0.191043  0.287149  ...           -0.217782   \n",
      "2013-11-04 -0.285653  0.191043  0.287149  0.222024  ...            0.083203   \n",
      "2013-11-05  0.191043  0.287149  0.222024 -1.041217  ...           -0.919373   \n",
      "2013-11-06  0.287149  0.222024 -1.041217  1.214520  ...           -0.781228   \n",
      "2013-11-07  0.222024 -1.041217  1.214520  1.488269  ...            0.936611   \n",
      "2013-11-08 -1.041217  1.214520  1.488269  0.127690  ...           -1.048634   \n",
      "2013-11-09  1.214520  1.488269  0.127690  0.129713  ...            1.411448   \n",
      "2013-11-10  1.488269  0.127690  0.129713  0.107706  ...           -0.001697   \n",
      "\n",
      "            difference_266_1-7  difference_266_1-6  difference_266_1-5  \\\n",
      "Date                                                                     \n",
      "2013-11-01           -0.341341           -0.217782            0.083203   \n",
      "2013-11-02           -0.217782            0.083203           -0.919373   \n",
      "2013-11-03            0.083203           -0.919373           -0.781228   \n",
      "2013-11-04           -0.919373           -0.781228            0.936611   \n",
      "2013-11-05           -0.781228            0.936611           -1.048634   \n",
      "2013-11-06            0.936611           -1.048634            1.411448   \n",
      "2013-11-07           -1.048634            1.411448           -0.001697   \n",
      "2013-11-08            1.411448           -0.001697            0.000804   \n",
      "2013-11-09           -0.001697            0.000804           -1.396647   \n",
      "2013-11-10            0.000804           -1.396647            2.672624   \n",
      "\n",
      "            difference_266_1-4  difference_266_1-3  difference_266_1-2  \\\n",
      "Date                                                                     \n",
      "2013-11-01           -0.919373           -0.781228            0.936611   \n",
      "2013-11-02           -0.781228            0.936611           -1.048634   \n",
      "2013-11-03            0.936611           -1.048634            1.411448   \n",
      "2013-11-04           -1.048634            1.411448           -0.001697   \n",
      "2013-11-05            1.411448           -0.001697            0.000804   \n",
      "2013-11-06           -0.001697            0.000804           -1.396647   \n",
      "2013-11-07            0.000804           -1.396647            2.672624   \n",
      "2013-11-08           -1.396647            2.672624           -1.864960   \n",
      "2013-11-09            2.672624           -1.864960            0.900123   \n",
      "2013-11-10           -1.864960            0.900123           -0.105574   \n",
      "\n",
      "            difference_266_1-1     tzero  Target_Tplus3  \n",
      "Date                                                     \n",
      "2013-11-01           -1.048634 -1.404379       0.006176  \n",
      "2013-11-02            1.411448  0.007069      -1.390471  \n",
      "2013-11-03           -0.001697  0.005372       1.282153  \n",
      "2013-11-04            0.000804  0.006176      -0.582807  \n",
      "2013-11-05           -1.396647 -1.390471       0.317317  \n",
      "2013-11-06            2.672624  1.282153       0.211742  \n",
      "2013-11-07           -1.864960 -0.582807       0.173192  \n",
      "2013-11-08            0.900123  0.317317       0.258448  \n",
      "2013-11-09           -0.105574  0.211742      -1.719385  \n",
      "2013-11-10           -0.038551  0.173192       1.015737  \n",
      "\n",
      "[10 rows x 570 columns]\n",
      "created dataframe for label\n",
      "            dcoilwtico_target\n",
      "Date                         \n",
      "2013-11-01           0.006176\n",
      "2013-11-02          -1.390471\n",
      "2013-11-03           1.282153\n",
      "2013-11-04          -0.582807\n",
      "2013-11-05           0.317317\n",
      "2013-11-06           0.211742\n",
      "2013-11-07           0.173192\n",
      "2013-11-08           0.258448\n",
      "2013-11-09          -1.719385\n",
      "2013-11-10           1.015737\n",
      "dropped the label in series\n",
      "renamed ARMA features for series\n",
      "            dcoilwtico_T-303  dcoilwtico_T-302  dcoilwtico_T-301  \\\n",
      "Date                                                               \n",
      "2013-11-01          0.000000         -0.136994          0.138958   \n",
      "2013-11-02         -0.136994          0.138958          0.031423   \n",
      "2013-11-03          0.138958          0.031423          0.025515   \n",
      "2013-11-04          0.031423          0.025515          0.031717   \n",
      "2013-11-05          0.025515          0.031717          0.010236   \n",
      "2013-11-06          0.031717          0.010236         -0.144876   \n",
      "2013-11-07          0.010236         -0.144876          0.665421   \n",
      "2013-11-08         -0.144876          0.665421         -0.285653   \n",
      "2013-11-09          0.665421         -0.285653          0.191043   \n",
      "2013-11-10         -0.285653          0.191043          0.287149   \n",
      "\n",
      "            dcoilwtico_T-300  dcoilwtico_T-299  dcoilwtico_T-298  \\\n",
      "Date                                                               \n",
      "2013-11-01          0.031423          0.025515          0.031717   \n",
      "2013-11-02          0.025515          0.031717          0.010236   \n",
      "2013-11-03          0.031717          0.010236         -0.144876   \n",
      "2013-11-04          0.010236         -0.144876          0.665421   \n",
      "2013-11-05         -0.144876          0.665421         -0.285653   \n",
      "2013-11-06          0.665421         -0.285653          0.191043   \n",
      "2013-11-07         -0.285653          0.191043          0.287149   \n",
      "2013-11-08          0.191043          0.287149          0.222024   \n",
      "2013-11-09          0.287149          0.222024         -1.041217   \n",
      "2013-11-10          0.222024         -1.041217          1.214520   \n",
      "\n",
      "            dcoilwtico_T-297  dcoilwtico_T-296  dcoilwtico_T-295  \\\n",
      "Date                                                               \n",
      "2013-11-01          0.010236         -0.144876          0.665421   \n",
      "2013-11-02         -0.144876          0.665421         -0.285653   \n",
      "2013-11-03          0.665421         -0.285653          0.191043   \n",
      "2013-11-04         -0.285653          0.191043          0.287149   \n",
      "2013-11-05          0.191043          0.287149          0.222024   \n",
      "2013-11-06          0.287149          0.222024         -1.041217   \n",
      "2013-11-07          0.222024         -1.041217          1.214520   \n",
      "2013-11-08         -1.041217          1.214520          1.488269   \n",
      "2013-11-09          1.214520          1.488269          0.127690   \n",
      "2013-11-10          1.488269          0.127690          0.129713   \n",
      "\n",
      "            dcoilwtico_T-294  ...  dcoilwtico_difference_266_1-9  \\\n",
      "Date                          ...                                  \n",
      "2013-11-01         -0.285653  ...                       0.474474   \n",
      "2013-11-02          0.191043  ...                       1.187271   \n",
      "2013-11-03          0.287149  ...                      -0.341341   \n",
      "2013-11-04          0.222024  ...                      -0.217782   \n",
      "2013-11-05         -1.041217  ...                       0.083203   \n",
      "2013-11-06          1.214520  ...                      -0.919373   \n",
      "2013-11-07          1.488269  ...                      -0.781228   \n",
      "2013-11-08          0.127690  ...                       0.936611   \n",
      "2013-11-09          0.129713  ...                      -1.048634   \n",
      "2013-11-10          0.107706  ...                       1.411448   \n",
      "\n",
      "            dcoilwtico_difference_266_1-8  dcoilwtico_difference_266_1-7  \\\n",
      "Date                                                                       \n",
      "2013-11-01                       1.187271                      -0.341341   \n",
      "2013-11-02                      -0.341341                      -0.217782   \n",
      "2013-11-03                      -0.217782                       0.083203   \n",
      "2013-11-04                       0.083203                      -0.919373   \n",
      "2013-11-05                      -0.919373                      -0.781228   \n",
      "2013-11-06                      -0.781228                       0.936611   \n",
      "2013-11-07                       0.936611                      -1.048634   \n",
      "2013-11-08                      -1.048634                       1.411448   \n",
      "2013-11-09                       1.411448                      -0.001697   \n",
      "2013-11-10                      -0.001697                       0.000804   \n",
      "\n",
      "            dcoilwtico_difference_266_1-6  dcoilwtico_difference_266_1-5  \\\n",
      "Date                                                                       \n",
      "2013-11-01                      -0.217782                       0.083203   \n",
      "2013-11-02                       0.083203                      -0.919373   \n",
      "2013-11-03                      -0.919373                      -0.781228   \n",
      "2013-11-04                      -0.781228                       0.936611   \n",
      "2013-11-05                       0.936611                      -1.048634   \n",
      "2013-11-06                      -1.048634                       1.411448   \n",
      "2013-11-07                       1.411448                      -0.001697   \n",
      "2013-11-08                      -0.001697                       0.000804   \n",
      "2013-11-09                       0.000804                      -1.396647   \n",
      "2013-11-10                      -1.396647                       2.672624   \n",
      "\n",
      "            dcoilwtico_difference_266_1-4  dcoilwtico_difference_266_1-3  \\\n",
      "Date                                                                       \n",
      "2013-11-01                      -0.919373                      -0.781228   \n",
      "2013-11-02                      -0.781228                       0.936611   \n",
      "2013-11-03                       0.936611                      -1.048634   \n",
      "2013-11-04                      -1.048634                       1.411448   \n",
      "2013-11-05                       1.411448                      -0.001697   \n",
      "2013-11-06                      -0.001697                       0.000804   \n",
      "2013-11-07                       0.000804                      -1.396647   \n",
      "2013-11-08                      -1.396647                       2.672624   \n",
      "2013-11-09                       2.672624                      -1.864960   \n",
      "2013-11-10                      -1.864960                       0.900123   \n",
      "\n",
      "            dcoilwtico_difference_266_1-2  dcoilwtico_difference_266_1-1  \\\n",
      "Date                                                                       \n",
      "2013-11-01                       0.936611                      -1.048634   \n",
      "2013-11-02                      -1.048634                       1.411448   \n",
      "2013-11-03                       1.411448                      -0.001697   \n",
      "2013-11-04                      -0.001697                       0.000804   \n",
      "2013-11-05                       0.000804                      -1.396647   \n",
      "2013-11-06                      -1.396647                       2.672624   \n",
      "2013-11-07                       2.672624                      -1.864960   \n",
      "2013-11-08                      -1.864960                       0.900123   \n",
      "2013-11-09                       0.900123                      -0.105574   \n",
      "2013-11-10                      -0.105574                      -0.038551   \n",
      "\n",
      "            dcoilwtico_tzero  \n",
      "Date                          \n",
      "2013-11-01         -1.404379  \n",
      "2013-11-02          0.007069  \n",
      "2013-11-03          0.005372  \n",
      "2013-11-04          0.006176  \n",
      "2013-11-05         -1.390471  \n",
      "2013-11-06          1.282153  \n",
      "2013-11-07         -0.582807  \n",
      "2013-11-08          0.317317  \n",
      "2013-11-09          0.211742  \n",
      "2013-11-10          0.173192  \n",
      "\n",
      "[10 rows x 569 columns]\n",
      "merged features from list\n",
      "merged labels from list\n",
      "created series for training\n",
      "dropped nas in the series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.001] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.05]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n",
      "/Users/cuburtbalanon/anaconda3/envs/varmann/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.05] before, using random point [0.001]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"oil.csv\")\n",
    "labels = ['dcoilwtico']\n",
    "date_column = 'date'\n",
    "model = train_model(df, labels, date_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "eb24fbde-4169-4514-b0b5-e30c34d8d5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_storage/model-new.sav']"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"model_storage\"\n",
    "local_model_storage_path = os.path.join(model_dir, \"model-new.sav\")\n",
    "joblib.dump(model, local_model_storage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca56b0-3110-4f9e-875a-7c1fb33c200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e293a2-0558-4957-8891-68ddfa66c286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
